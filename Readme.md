# üìÑ Semantic Multimodal RAG System

An end-to-end **Semantic Search--based Retrieval Augmented Generation
(RAG) application** built using **Streamlit, LangChain, ChromaDB,
HuggingFace embeddings, Groq LLM, and Perplexity API**.

This system enables **document-grounded question answering** over **PDF
and DOCX files**, supporting **text, tables, and images**, while
strictly minimizing hallucinations by forcing answers to be generated
**only from retrieved document context**.

------------------------------------------------------------------------

## üöÄ Key Features

‚Ä¢ Multimodal document understanding (Text, Tables, Images)\
‚Ä¢ Semantic vector-based retrieval\
‚Ä¢ Multi-vector (parent--child) indexing strategy\
‚Ä¢ Multi-question decomposition and answering\
‚Ä¢ Strict context-only answer generation\
‚Ä¢ Streamlit-based interactive UI

------------------------------------------------------------------------

## üß† System Overview

The application follows a research-grade RAG pipeline:

1.  User uploads multiple documents (PDF / DOCX)
2.  Documents are parsed into structured elements
3.  Text, tables, and images are summarized
4.  Summaries are embedded into a vector database
5.  Parent documents are stored for full-context recovery
6.  User queries are semantically matched
7.  Retrieved context is injected into an LLM prompt
8.  Final answers are generated without external knowledge

------------------------------------------------------------------------

## üìÇ Architecture\Workflow

![Architecture Diagram](diagram_2.jpeg)


------------------------------------------------------------------------

## üìÇ Project Structure

frontend\
‚Ä¢ Streamlit application interface

extraction\
‚Ä¢ PDF and DOCX parsing logic

summarization\
‚Ä¢ Text and table summarization (Groq)\
‚Ä¢ Image summarization (Perplexity Vision)

rag\
‚Ä¢ Vector store setup\
‚Ä¢ Multi-vector retriever\
‚Ä¢ RAG chain construction

perplexity_api\
‚Ä¢ API wrapper for Perplexity LLM

------------------------------------------------------------------------

## üîç Retrieval Design

The system uses **semantic similarity search only**, avoiding keyword or
lexical matching.

A **MultiVectorRetriever** is used: ‚Ä¢ Child documents contain summarized
chunks (embedded) ‚Ä¢ Parent documents contain full original content ‚Ä¢ A
shared document ID links both

This design ensures: ‚Ä¢ Fast semantic retrieval ‚Ä¢ Complete context
availability ‚Ä¢ Reduced hallucination risk

------------------------------------------------------------------------

## üñºÔ∏è Multimodal Support

Text: ‚Ä¢ Extracted and summarized using Groq LLM

Tables: ‚Ä¢ Converted to HTML ‚Ä¢ Summarized before embedding

Images: ‚Ä¢ Encoded to base64 ‚Ä¢ Summarized using Perplexity Vision API ‚Ä¢
Safely validated and size-checked

------------------------------------------------------------------------

## ‚ùì Multi-Question Handling

User queries containing multiple questions are automatically split. Each
sub-question is: ‚Ä¢ Retrieved independently ‚Ä¢ Answered independently ‚Ä¢
Returned in a structured format

------------------------------------------------------------------------

## üõ°Ô∏è Hallucination Control

The system enforces: ‚Ä¢ Context-only prompting ‚Ä¢ No pretrained knowledge
usage ‚Ä¢ No answer generation without retrieved context ‚Ä¢ Explicit LLM
instructions to avoid assumptions

This makes the system suitable for **academic, research, and evaluation
use cases**.

------------------------------------------------------------------------

## üñ•Ô∏è User Interface

The Streamlit UI allows users to: ‚Ä¢ Upload multiple documents ‚Ä¢ Choose
answer mode (response only / response with source) ‚Ä¢ Ask natural
language questions ‚Ä¢ View grounded answers

Documents are indexed only once per session for efficiency.

------------------------------------------------------------------------

## ‚öôÔ∏è Environment Setup

Python virtual environment is recommended.

Environment variables required: ‚Ä¢ GROQ_API_KEY ‚Ä¢ PERPLEXITY_API_KEY

These must be stored in a `.env` file.

------------------------------------------------------------------------

## ‚ñ∂Ô∏è Running the Application

Start the Streamlit app and open it in a browser. The system runs fully
locally except for LLM API calls.

------------------------------------------------------------------------

## üéØ Use Cases

‚Ä¢ Research paper question answering\
‚Ä¢ Technical documentation analysis\
‚Ä¢ Academic project demonstrations\
‚Ä¢ Multimodal knowledge bases\
‚Ä¢ RAG interview and viva preparation

------------------------------------------------------------------------

## üîÆ Future Enhancements

‚Ä¢ Cross-encoder reranking\
‚Ä¢ Agent-based query planning\
‚Ä¢ Persistent vector databases\
‚Ä¢ OCR for scanned PDFs\
‚Ä¢ UI-level citation highlighting

------------------------------------------------------------------------

## üìå Summary

This project demonstrates a **clean, explainable, and production-aligned
RAG architecture** with strong emphasis on: ‚Ä¢ Retrieval correctness\
‚Ä¢ Multimodal reasoning\
‚Ä¢ Hallucination reduction\
‚Ä¢ Interview-readiness

It is ideal for demonstrating **deep understanding of modern RAG
systems**.